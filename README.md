# ğŸš¢ Titanic Survival Prediction

Un progetto di Machine Learning per prevedere la sopravvivenza dei passeggeri del Titanic, basato sul dataset classico reso disponibile da Kaggle.
Include analisi dei dati, feature engineering, modelli predittivi (albero decisionale, regressione lineare) e ottimizzazione tramite Grid Search.
ğŸ“ Struttura del progetto

titanic_project/
â”œâ”€â”€ titanic_cleaned.csv         # Dataset preprocessato
â”œâ”€â”€ titanic_features.csv        # Features pronte per il modello
â”œâ”€â”€ titanic_target.csv          # Variabile target (Sopravvissuto)
â”œâ”€â”€ features.py                 # Funzione di feature engineering
â”œâ”€â”€ decision_tree_model.py      # Modello Decision Tree + valutazione
â”œâ”€â”€ grid_search_dt.py           # Decision Tree con Grid Search
â”œâ”€â”€ linear_regression_model.py  # Regressione lineare e valutazione
â”œâ”€â”€ outlier_removal.py          # Rimozione outlier con IQR
â”œâ”€â”€ README.md                   # Questo file

# ğŸ“Š Dataset

Il dataset originale Ã¨ stato preprocessato per includere:

    Gestione dei valori mancanti

    Codifica delle variabili categoriche (Sex, Embarked, ecc.)

    Normalizzazione e scaling

    Creazione di nuove feature

ğŸ§  Modelli implementati
ğŸ”¹ Decision Tree Classifier

    Valutazione con Accuracy, Classification Report, Confusion Matrix

    Visualizzazione ad albero

    Ottimizzazione con GridSearchCV

ğŸ”¹ Linear Regression

    Utilizzata per classificazione binaria con soglia (â‰¥ 0.5)

    Valutazione con RÂ², RMSE, e Accuracy

    Conversione da regressione continua a classificazione

ğŸ“ˆ Analisi e Visualizzazione

    Box plot per lâ€™individuazione degli outlier

    Rimozione outlier tramite metodo IQR

    Heatmap della matrice di confusione

    Grafici interpretativi con Matplotlib e Seaborn

âš™ï¸ Setup e Requisiti

Assicurati di avere Python 3.8+ e installa le dipendenze principali:

pip install -r requirements.txt

Contenuto esempio di requirements.txt:

pandas
numpy
scikit-learn
matplotlib
seaborn

â–¶ï¸ Esecuzione

Esempio per allenare e testare il Decision Tree:

python decision_tree_model.py

Esempio per eseguire la Grid Search:

python grid_search_dt.py

âœ… Risultati ottenuti

    Accuracy finale (Decision Tree ottimizzato): ~0.82

    Migliori parametri trovati via Grid Search

    Identificazione e rimozione outlier per miglioramento del dataset
